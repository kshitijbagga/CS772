{"metadata":{"kernelspec":{"name":"","display_name":""},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":11639033,"sourceType":"datasetVersion","datasetId":7303071}],"dockerImageVersionId":31011,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":5,"nbformat":4,"cells":[{"id":"6f233884-5d03-4f0d-8cf9-1b0fbc662201","cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport pyro\nimport pyro.distributions as dist\nfrom pyro.infer import SVI, Trace_ELBO\nfrom pyro.optim import ClippedAdam\nimport numpy as np\nimport pandas as pd\nimport glob, os\nfrom sklearn.metrics import mean_squared_error","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-01T17:28:03.663821Z","iopub.execute_input":"2025-05-01T17:28:03.664134Z","iopub.status.idle":"2025-05-01T17:28:04.478794Z","shell.execute_reply.started":"2025-05-01T17:28:03.664114Z","shell.execute_reply":"2025-05-01T17:28:04.478272Z"}},"outputs":[],"execution_count":16},{"id":"2ae68501-43b2-4ed3-bf4a-1d25a7076b64","cell_type":"code","source":"# --- Load and prepare data ---\ndef load_data(data_dir, seq_len=18):\n    paths = sorted(\n        glob.glob(os.path.join(data_dir, \"IPF_Final_*.csv\")),\n        key=lambda p: int(os.path.basename(p).split('_')[2].split('.')[0])\n    )\n    assert len(paths) >= seq_len + 1, f\"Need at least {seq_len + 1} CSV files for full sequence + target.\"\n\n    arrays = [np.loadtxt(path, delimiter=',', skiprows=1, usecols=(1, 2, 3)) for path in paths[:seq_len + 1]]\n    X_seq = np.stack(arrays[:seq_len], axis=0)\n    Y_arr = arrays[seq_len]\n\n    x_tensor = torch.tensor(X_seq.transpose(1, 0, 2), dtype=torch.float32)\n    y_tensor = torch.tensor(Y_arr, dtype=torch.float32)\n    return x_tensor, y_tensor\n\ndata_dir = \"/kaggle/input/training/Training Dataset\"\nseq_len = 18\nx_full, y_full = load_data(data_dir, seq_len)\nx_full = x_full.to(device)\ny_full = y_full.to(device)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-01T17:28:07.294157Z","iopub.execute_input":"2025-05-01T17:28:07.295129Z","iopub.status.idle":"2025-05-01T17:28:07.449562Z","shell.execute_reply.started":"2025-05-01T17:28:07.295098Z","shell.execute_reply":"2025-05-01T17:28:07.448973Z"}},"outputs":[],"execution_count":17},{"id":"82ffe3f8-e066-4bbe-870b-ff4f4080db0f","cell_type":"code","source":"class MultiLSTMBackbone(nn.Module):\n    def __init__(self, input_size=3, hidden_size=64):\n        super().__init__()\n        self.lstm_phi1 = nn.LSTM(input_size, hidden_size, batch_first=True)\n        self.lstm_phi = nn.LSTM(input_size, hidden_size, batch_first=True)\n        self.lstm_phi2 = nn.LSTM(input_size, hidden_size, batch_first=True)\n\n        self.fc_phi1 = nn.Linear(hidden_size * 3, 1)\n        self.fc_phi = nn.Linear(hidden_size * 3, 1)\n        self.fc_phi2 = nn.Linear(hidden_size * 3, 1)\n\n    def forward(self, x):\n        _, (h1, _) = self.lstm_phi1(x)\n        _, (h2, _) = self.lstm_phi(x)\n        _, (h3, _) = self.lstm_phi2(x)\n        h_cat = torch.cat([h1[-1], h2[-1], h3[-1]], dim=1)\n        out1 = self.fc_phi1(h_cat)\n        out2 = self.fc_phi(h_cat)\n        out3 = self.fc_phi2(h_cat)\n        return out1, out2, out3","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-01T17:32:14.989957Z","iopub.execute_input":"2025-05-01T17:32:14.990259Z","iopub.status.idle":"2025-05-01T17:32:14.996328Z","shell.execute_reply.started":"2025-05-01T17:32:14.990239Z","shell.execute_reply":"2025-05-01T17:32:14.995554Z"}},"outputs":[],"execution_count":26},{"id":"04442118-ed8e-40ee-b859-b6a0bafbb0e8","cell_type":"code","source":"def model_fn(x, y=None):\n    y1, y2, y3 = (y[:, 0:1], y[:, 1:2], y[:, 2:3]) if y is not None else (None, None, None)\n\n    _, (h1, _) = model.lstm_phi1(x)\n    _, (h2, _) = model.lstm_phi(x)\n    _, (h3, _) = model.lstm_phi2(x)\n    h_combined = torch.cat([h1[-1], h2[-1], h3[-1]], dim=1)\n\n    w1 = pyro.sample(\"w1\", dist.Normal(model.fc_phi1.weight, 0.5).to_event(2))\n    b1 = pyro.sample(\"b1\", dist.Normal(model.fc_phi1.bias, 0.5).to_event(1))\n    w2 = pyro.sample(\"w2\", dist.Normal(model.fc_phi.weight, 0.5).to_event(2))\n    b2 = pyro.sample(\"b2\", dist.Normal(model.fc_phi.bias, 0.5).to_event(1))\n    w3 = pyro.sample(\"w3\", dist.Normal(model.fc_phi2.weight, 0.5).to_event(2))\n    b3 = pyro.sample(\"b3\", dist.Normal(model.fc_phi2.bias, 0.5).to_event(1))\n\n    mean1 = h_combined @ w1.t() + b1\n    mean2 = h_combined @ w2.t() + b2\n    mean3 = h_combined @ w3.t() + b3\n\n    with pyro.plate(\"data\", x.shape[0]):\n        pyro.sample(\"obs1\", dist.Normal(mean1, 5.0).to_event(1), obs=y1)\n        pyro.sample(\"obs2\", dist.Normal(mean2, 5.0).to_event(1), obs=y2)\n        pyro.sample(\"obs3\", dist.Normal(mean3, 5.0).to_event(1), obs=y3)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-01T17:32:17.039759Z","iopub.execute_input":"2025-05-01T17:32:17.040626Z","iopub.status.idle":"2025-05-01T17:32:17.048748Z","shell.execute_reply.started":"2025-05-01T17:32:17.040591Z","shell.execute_reply":"2025-05-01T17:32:17.048189Z"}},"outputs":[],"execution_count":27},{"id":"4d7423b3-3082-4e53-9c0e-0dd3f93a65fa","cell_type":"code","source":"def guide_fn(x, y=None):\n    for i, head in enumerate([model.fc_phi1, model.fc_phi, model.fc_phi2], start=1):\n        pyro.param(f\"w{i}_loc\", head.weight.detach().clone())\n        pyro.param(f\"w{i}_scale\", torch.ones_like(head.weight) * 0.5, constraint=dist.constraints.positive)\n        pyro.param(f\"b{i}_loc\", head.bias.detach().clone())\n        pyro.param(f\"b{i}_scale\", torch.ones_like(head.bias) * 0.5, constraint=dist.constraints.positive)\n\n        pyro.sample(f\"w{i}\", dist.Normal(pyro.param(f\"w{i}_loc\"), pyro.param(f\"w{i}_scale\")).to_event(2))\n        pyro.sample(f\"b{i}\", dist.Normal(pyro.param(f\"b{i}_loc\"), pyro.param(f\"b{i}_scale\")).to_event(1))\n\n\n# Instantiate model\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel = MultiLSTMBackbone().to(device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-01T17:32:18.574533Z","iopub.execute_input":"2025-05-01T17:32:18.575239Z","iopub.status.idle":"2025-05-01T17:32:18.585384Z","shell.execute_reply.started":"2025-05-01T17:32:18.575215Z","shell.execute_reply":"2025-05-01T17:32:18.584660Z"}},"outputs":[],"execution_count":28},{"id":"7348b6a8-6f0f-4c38-86b6-5d426c8a3f53","cell_type":"code","source":"# --- LSTM Backbone Pretraining ---\nprint(\"üîß Pretraining deterministic LSTM backbone...\")\nbackbone_optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\nloss_fn = nn.MSELoss()\n\nmodel.train()\nfor epoch in range(2000):\n    backbone_optimizer.zero_grad()\n    out1, out2, out3 = model(x_full)\n    loss = (\n        0.33 * loss_fn(out1, y_full[:, 0:1]) +\n        0.33 * loss_fn(out2, y_full[:, 1:2]) +\n        0.34 * loss_fn(out3, y_full[:, 2:3])\n    )\n    loss.backward()\n    backbone_optimizer.step()\n    if (epoch + 1) % 100 == 0:\n        print(f\"Epoch {epoch + 1} LSTM Backbone Loss: {loss:.2f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-01T17:33:21.651771Z","iopub.execute_input":"2025-05-01T17:33:21.652368Z","iopub.status.idle":"2025-05-01T17:35:39.539508Z","shell.execute_reply.started":"2025-05-01T17:33:21.652343Z","shell.execute_reply":"2025-05-01T17:35:39.538711Z"}},"outputs":[{"name":"stdout","text":"üîß Pretraining deterministic LSTM backbone...\nEpoch 100 LSTM Backbone Loss: 2092.07\nEpoch 200 LSTM Backbone Loss: 1832.75\nEpoch 300 LSTM Backbone Loss: 1595.78\nEpoch 400 LSTM Backbone Loss: 1381.92\nEpoch 500 LSTM Backbone Loss: 1195.73\nEpoch 600 LSTM Backbone Loss: 1035.11\nEpoch 700 LSTM Backbone Loss: 896.31\nEpoch 800 LSTM Backbone Loss: 780.35\nEpoch 900 LSTM Backbone Loss: 683.00\nEpoch 1000 LSTM Backbone Loss: 600.45\nEpoch 1100 LSTM Backbone Loss: 530.93\nEpoch 1200 LSTM Backbone Loss: 474.01\nEpoch 1300 LSTM Backbone Loss: 424.84\nEpoch 1400 LSTM Backbone Loss: 384.92\nEpoch 1500 LSTM Backbone Loss: 349.46\nEpoch 1600 LSTM Backbone Loss: 320.50\nEpoch 1700 LSTM Backbone Loss: 293.34\nEpoch 1800 LSTM Backbone Loss: 269.06\nEpoch 1900 LSTM Backbone Loss: 249.05\nEpoch 2000 LSTM Backbone Loss: 229.61\n","output_type":"stream"}],"execution_count":30},{"id":"eff7eeae-6048-4119-a6d0-5691f21c1987","cell_type":"code","source":"# --- VI Training ---\npyro.clear_param_store()\noptimizer = ClippedAdam({\"lr\": 1e-3})\nsvi = SVI(model_fn, guide_fn, optimizer, loss=Trace_ELBO())\n\n# Run SVI for multiple steps with early stopping\nprint(\"üîÅ Running Variational Inference with early stopping...\")\nnum_steps = 2000\npatience = 100\nmin_delta = 1.0\nbest_loss = float('inf')\nno_improve_count = 0\n\nfor step in range(num_steps):\n    loss = svi.step(x_full, y_full)\n\n    if loss < best_loss - min_delta:\n        best_loss = loss\n        no_improve_count = 0\n    else:\n        no_improve_count += 1\n\n    if (step + 1) % 100 == 0:\n        print(f\"Step {step + 1} \tELBO Loss: {loss:.2f}\")\n\n    if no_improve_count >= patience:\n        print(f\"‚èπÔ∏è Early stopping at step {step + 1} due to no improvement.\")\n        break\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-01T17:37:50.231564Z","iopub.execute_input":"2025-05-01T17:37:50.231843Z","iopub.status.idle":"2025-05-01T17:38:41.078598Z","shell.execute_reply.started":"2025-05-01T17:37:50.231824Z","shell.execute_reply":"2025-05-01T17:38:41.077773Z"}},"outputs":[{"name":"stdout","text":"üîÅ Running Variational Inference with early stopping...\nStep 100 \tELBO Loss: 211556.23\nStep 200 \tELBO Loss: 215390.72\nStep 300 \tELBO Loss: 211705.99\nStep 400 \tELBO Loss: 202261.13\nStep 500 \tELBO Loss: 189673.01\nStep 600 \tELBO Loss: 193629.38\n‚èπÔ∏è Early stopping at step 631 due to no improvement.\n","output_type":"stream"}],"execution_count":31},{"id":"e11f6432-3839-4f9e-b4bf-44e8f10aacd2","cell_type":"code","source":"# --- Inference using variational posterior mean ---\nmodel.eval()\nwith torch.no_grad():\n    _, (h1, _) = model.lstm_phi1(x_full)\n    _, (h2, _) = model.lstm_phi(x_full)\n    _, (h3, _) = model.lstm_phi2(x_full)\n    h_combined = torch.cat([h1[-1], h2[-1], h3[-1]], dim=1)\n\n    phi1 = h_combined @ pyro.param(\"w1_loc\").t() + pyro.param(\"b1_loc\")\n    phi  = h_combined @ pyro.param(\"w2_loc\").t() + pyro.param(\"b2_loc\")\n    phi2 = h_combined @ pyro.param(\"w3_loc\").t() + pyro.param(\"b3_loc\")\n\n    preds = torch.cat([phi1, phi, phi2], dim=1).cpu().numpy()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-01T17:39:58.989268Z","iopub.execute_input":"2025-05-01T17:39:58.990006Z","iopub.status.idle":"2025-05-01T17:39:59.056771Z","shell.execute_reply.started":"2025-05-01T17:39:58.989985Z","shell.execute_reply":"2025-05-01T17:39:59.056281Z"}},"outputs":[],"execution_count":32},{"id":"66a7155a-73c2-4bae-a15f-2d616ea0f309","cell_type":"code","source":"# Save prediction and compute RMSE\ny_true_np = y_full.cpu().numpy()\nrmse = np.sqrt(np.mean((preds - y_true_np) ** 2))\nprint(f\"‚úÖ Final VI RMSE: {rmse:.4f} degrees\")\n\ndf = pd.DataFrame(preds, columns=[\"Phi1\", \"Phi\", \"Phi2\"])\nPhase = [1 for i in range(len(df))]\ndf[\"Phase\"] = Phase\ndf = df[[\"Phase\", \"Phi1\", \"Phi\", \"Phi2\"]]\ndf.to_csv(\"IPF_20_pred.csv\", index=False)\nprint(\"‚úÖ Prediction for 20th timestep saved to IPF_20_pred.csv\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-01T17:48:49.859628Z","iopub.execute_input":"2025-05-01T17:48:49.860318Z","iopub.status.idle":"2025-05-01T17:48:49.929230Z","shell.execute_reply.started":"2025-05-01T17:48:49.860296Z","shell.execute_reply":"2025-05-01T17:48:49.928518Z"}},"outputs":[{"name":"stdout","text":"‚úÖ Final VI RMSE: 13.3633 degrees\n‚úÖ Prediction for 20th timestep saved to IPF_20_pred.csv\n","output_type":"stream"}],"execution_count":34},{"id":"3782b246-89e8-4ccf-9225-fadbc6f12737","cell_type":"code","source":"# This is the RMSE for model training\n# For model evaluation, predict the 21% strained microstructure and compare with actual data.","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}